{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Whether you are migrating existing workloads or creating something new in AWS, it can be tempting to bring your current security solutions with you. In this hands-on workshop, we help you identify which cloud-native solutions can mitigate the same risks while providing scalability, reliability, and cost optimization at a low operational burden. During this workshop, you will learn how to use cloud native controls like CloudTrail, Security Groups, GuardDuty and many more, to secure your cloud architecture. Level : Intermediate Duration : 1 hour Prerequisites : AWS Account, Admin IAM User CSF Functions : Prevent, Detect CAF Components : Preventative, Detective for Logging and Monitoring and Infrastructure Security AWS Services : Amazon CloudWatch, Amazon GuardDuty, AWS CloudTrail, AWS Config, Security Groups, Network ACLs Scenario For this workshop, you will be securing an architecture that was a \"refactored\" migration from a traditional three tier on premise architecture. The network has two internet facing VPCs - one VPC for the Web Application and one sandbox for the developers called the Proof of Concept VPC. Additionally, there is a Services VPC that allows administrators to manage the network. Architecture Presentation Deck Workshop Presentation Deck Region This workshop has been tested in us-east-1 , us-east-2 , and us-west-1 First you'll want to Set up your environment for this lab by running CloudFormation. Then you will perform multiple steps that will guide you through different security tasks. These steps will have you diving deep into two of the Core Epics of the Cloud Adoption Framework, namely \"Logging and Monitoring\" and \"Infrastructure Security\": Enable granular logging Improve granular control of communication Improve granular network-based controls Evaluate detailed logging capabilities Evaluate network-based protections Minimize admin access risk If you complete all six steps with time to spare, there is Extra Credit available. Finally, make sure to Clean up your environment to ensure you don't have any continuing charges. Many of the steps in this lab are written in general steps. This is intentional - we want you to learn the AWS interface, so we will not always specify each necessary click to accomplish a task. We've written more of a guide than a tutorial. Please don\u2019t hesitate to ask questions.","title":"Overview"},{"location":"#overview","text":"Whether you are migrating existing workloads or creating something new in AWS, it can be tempting to bring your current security solutions with you. In this hands-on workshop, we help you identify which cloud-native solutions can mitigate the same risks while providing scalability, reliability, and cost optimization at a low operational burden. During this workshop, you will learn how to use cloud native controls like CloudTrail, Security Groups, GuardDuty and many more, to secure your cloud architecture. Level : Intermediate Duration : 1 hour Prerequisites : AWS Account, Admin IAM User CSF Functions : Prevent, Detect CAF Components : Preventative, Detective for Logging and Monitoring and Infrastructure Security AWS Services : Amazon CloudWatch, Amazon GuardDuty, AWS CloudTrail, AWS Config, Security Groups, Network ACLs","title":"Overview"},{"location":"#scenario","text":"For this workshop, you will be securing an architecture that was a \"refactored\" migration from a traditional three tier on premise architecture. The network has two internet facing VPCs - one VPC for the Web Application and one sandbox for the developers called the Proof of Concept VPC. Additionally, there is a Services VPC that allows administrators to manage the network.","title":"Scenario"},{"location":"#architecture","text":"","title":"Architecture"},{"location":"#presentation-deck","text":"Workshop Presentation Deck","title":"Presentation Deck"},{"location":"#region","text":"This workshop has been tested in us-east-1 , us-east-2 , and us-west-1 First you'll want to Set up your environment for this lab by running CloudFormation. Then you will perform multiple steps that will guide you through different security tasks. These steps will have you diving deep into two of the Core Epics of the Cloud Adoption Framework, namely \"Logging and Monitoring\" and \"Infrastructure Security\": Enable granular logging Improve granular control of communication Improve granular network-based controls Evaluate detailed logging capabilities Evaluate network-based protections Minimize admin access risk If you complete all six steps with time to spare, there is Extra Credit available. Finally, make sure to Clean up your environment to ensure you don't have any continuing charges. Many of the steps in this lab are written in general steps. This is intentional - we want you to learn the AWS interface, so we will not always specify each necessary click to accomplish a task. We've written more of a guide than a tutorial. Please don\u2019t hesitate to ask questions.","title":"Region"},{"location":"cleanup/","text":"In order to avoid unnecessary ongoing expenses, make sure to clean up all the resources you created in this lab. Empty and Delete your cloudsecurity-demo-bucket-{myname} bucket Empty and Delete your cloudsecurity-ssmlogs-bucket-{myname} bucket If you got this far Stop Config charges by going to Settings and clicking the Turn off button to disable the Configuration Recorder. Empty and Delete your Config Bucket . If you selected the default, that will likely be named config-bucket-ACCTIDXXXXXX Delete your CloudTrail Trail Disable GuardDuty In VPC , go to the NACLs you created and disassociate them from any subnets. Now Delete the NACLs . In CloudFormation Delete your Stack Wait until this is complete","title":"Clean Up"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"extracredit/","text":"Extra Credit Section Log all commands Logging all commands There is a way to log all commands sent to the instance as well. First, you have to create S3 buckets and CloudWatch Logs. Go to S3 . Create a Bucket called cloudsecurity-ssmlogs-bucket-{myname} . Before you move on, turn on Default Encryption using AWS-KMS and the aws/s3 Then Grant Amazon S3 Log Delivery group write access to the bucket . Go to CloudWatch . In Logs you must Create log group , called cloudsecurity-ssmlogs-logs . Go to IAM . We will modify the Role called SharedServerConnectivityRole Expand the Inline Policy and click Edit Policy Add additional permissions including S3 Write Bucket : Any Object : Any CloudWatch Logs Write Log Group Log Stream logs:DescribeLogGroups logs:DescribeLogStreams EC2 Messages GetMessages Systems Manager ListInstanceAssociations UpdateInstanceAssociationsStatus Review the policy and Save Changes If there are any errors, go to Previous and keep adding Any to the resources the policy requires defined. This can be more restrictive in a production environment. Now go back to Systems Manager , Session Manager . Let\u2019s use Preferences to set up logging. Edit the settings to Write session output and choose the bucket called \u201c cloudsecurity-ssmlogs-bucket-{myname} \u201d. Let\u2019s also send the output to Cloudwatch logs , we can deselect Encrypt Log Data , and create a log group name \u201c cloudsecurity-demo-bucket-{myname} \u201d. * In production I would not recommend storing unencrypted logs. Save that configuration. Now back at Sessions , you can Start a session with any server with the SSM agent and access to the SSM Service. TOKEN=`curl -X PUT http://169.254.169.254/latest/api/token -H X-aws-ec2-metadata-token-ttl-seconds: 21600 ` curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/instance-id curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/security-groups curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/iam/security-credentials/SharedServerConnectivityRole Terminate the connection. Checking Session History you will see the Output Location of your log. Look at the CloudWatch Logs of your session and see what commands you typed. Now that you've completed the extra credit, you should continue to continue with cleanup .","title":"Extra Credit"},{"location":"extracredit/#extra-credit-section","text":"Log all commands","title":"Extra Credit Section"},{"location":"extracredit/#logging-all-commands","text":"There is a way to log all commands sent to the instance as well. First, you have to create S3 buckets and CloudWatch Logs. Go to S3 . Create a Bucket called cloudsecurity-ssmlogs-bucket-{myname} . Before you move on, turn on Default Encryption using AWS-KMS and the aws/s3 Then Grant Amazon S3 Log Delivery group write access to the bucket . Go to CloudWatch . In Logs you must Create log group , called cloudsecurity-ssmlogs-logs . Go to IAM . We will modify the Role called SharedServerConnectivityRole Expand the Inline Policy and click Edit Policy Add additional permissions including S3 Write Bucket : Any Object : Any CloudWatch Logs Write Log Group Log Stream logs:DescribeLogGroups logs:DescribeLogStreams EC2 Messages GetMessages Systems Manager ListInstanceAssociations UpdateInstanceAssociationsStatus Review the policy and Save Changes If there are any errors, go to Previous and keep adding Any to the resources the policy requires defined. This can be more restrictive in a production environment. Now go back to Systems Manager , Session Manager . Let\u2019s use Preferences to set up logging. Edit the settings to Write session output and choose the bucket called \u201c cloudsecurity-ssmlogs-bucket-{myname} \u201d. Let\u2019s also send the output to Cloudwatch logs , we can deselect Encrypt Log Data , and create a log group name \u201c cloudsecurity-demo-bucket-{myname} \u201d. * In production I would not recommend storing unencrypted logs. Save that configuration. Now back at Sessions , you can Start a session with any server with the SSM agent and access to the SSM Service. TOKEN=`curl -X PUT http://169.254.169.254/latest/api/token -H X-aws-ec2-metadata-token-ttl-seconds: 21600 ` curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/instance-id curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/security-groups curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/iam/security-credentials/SharedServerConnectivityRole Terminate the connection. Checking Session History you will see the Output Location of your log. Look at the CloudWatch Logs of your session and see what commands you typed. Now that you've completed the extra credit, you should continue to continue with cleanup .","title":"Logging all commands"},{"location":"labsteps/","text":"Mitigate Risks Using Cloud-Native Infrastructure Security Lab Sections Enable granular logging Improve granular control of communication Improve granular network-based controls Evaluate detailed logging capabilities Evaluate network-based protections Minimize admin access risk Enable granular logging to see everything in your AWS environment We want to enable detailed, holistic logging and network-based security monitoring. Go to the CloudTrail service in the console. If it appears, click on Getting Started. We want to Create trail . Let\u2019s set a Trail Name of \u201c All-API-Commands-across-all-Regions \u201d. We should save these for further evaluation, so you would want to Create a new S3 bucket and call it \u201c cloudsecurity-demo-bucket-{myname} \u201d. (Don\u2019t forget, S3 buckets must have unique names, so make sure to add your name at the end. They can also only be lower case letters, numbers, \u201c-\u201c, and \u201c.\u201d) Log file encryption will be enabled by default. Give it the name of a new KMS key to use for the encryption by specifiying \" cloudsecurity-demo-kms-key \". Now we'll get the option to pick what Events we want to record. Make sure to select Management Events , with Read / Write activity, at minimum. These options will show us every API call made to our AWS environment moving forward. What are your other options? When would you want to enable those? Click Create to finalize the trail. We can come back to look at the results later. Monitoring what API calls are made is great, but it\u2019s difficult to convert that into something like Change Management for all infrastructure in the cloud. Is there a service to help there? Let us also look into one of the Services called Config . After Getting Started we can start tracking All resources, Including Global Resources AWS does a good job of clearly defining roles, so let\u2019s allow AWS to Create AWS Config service-linked role We would want to store this data in a central bucket as well. Let\u2019s Create a new bucket and use the default to ensure it's unique. Note: We could use the bucket we just created, but you would have to add permissions, which would take more time. Next , we can choose rules we want to test against, but we can do that later too if we skip it for now. Confirm these choices to enable Config to monitor all changes to our environment. And we\u2019ll see that in a bit. Now that we\u2019ve got good logging of the Control Plane (API commands and Changes to the environment), let\u2019s turn on logging of the Data Plane. Then, let us use a Service like GuardDuty to monitor logs in near real time for security anomalies. After Getting Started we can quickly enable this service with just one click. It\u2019s that easy. We'll check out what GuardDuty monitoring is later. When we looked at our on-premises environment we identified that disjointed security tooling, lack of insight into what\u2019s going on in the environment, and difficulty managing change control and permissions in the environment all led to risks becoming problems pretty fast. With the services we just enabled, we\u2019ll see how we now have complete insight into who\u2019s doing what in the environment, what changes are being made, and if and when problems start to arise. Granular, Provable Control of Communications Let's review and improve upon granular control of communication between workloads in the cloud. Looking at the granular control of system-to-system communication used to be difficult. Now, looking at your EC2 Service Security Groups allows you to quickly see who can talk to whom. Picking a Security Group like the Services Server Security Group we can see the more traditional way of doing things. Checking the Outbound rules, we see the servers can talk to a range of IP\u2019s, 65,536 to be precise. But there are only maybe 6-8 servers that they actually need to talk to. Well, if we copy the Security Group ID of the PoC Web Server Security Group we can start to reduce that number Edit the Outbound set of rules for the Services Server Security Group . Delete the 10.0.0.0/16 rule. Then, make a new rule with the Security Group name you copied. Save this and you\u2019ll see the Destination of the rule now shows the Security Group you listed. You can repeat this by Edit ing and Adding Rule s for each security group you want to allow access to. In doing this, you\u2019ve reduced the scope of internal traffic communication from 65,636 host down to 8. Additionally, if you ever need to stand up more servers in these groups, they would be automatically accessible without intervention, as long as you put them in the same Security Group. On premise, you would either need to have Firewalls between all internal VLAN\u2019s, Routers, and sites or complex Network ACL\u2019s on every switch in your environment. This reduces the risk of threats, the risk of misconfiguration, and the operational burden all at once. When Security includes explicitly denying network access Let's improve on our network-based controls by using Network ACLs to prevent lateral movement in a granular way. Security Groups are awesome at allowing access, but in VPC Services, Network ACLs are great at explicitly blocking them. For instance, if you wanted to make sure you explicitly blocked the Load Balancer in my WebApp from talking to my Database servers, you could Create a network ACL . You can name it \u201c LoadBalancerIsolation \u201d and put it in the Web Application VPC . After selecting the new network ACL, add an Outbound Rule by Editing Outbound Rules Adding Rules like these would block whatever Subnet you apply this to from talking to the Database Subnets but still allow access to the rest of the network, including the Web and Services VPC. Note that NACLs are evaluated in the specific order of their Rule #. Rule #: 50 Of type All Traffic To the Destination 10.0.2.0/24 And a Deny Behavior and Rule #: 60 Of type All Traffic To the Destination 10.0.130.0/24 And a Deny Behavior and Rule #: 100 Of type All Traffic To the Destination 0.0.0.0/0 And an Allow Behavior After Saving you need to allow access to that subnet from the internet, so recreating the All Traffic Allow rule for Inbound Rules is necessary. Add a Rule Rule #: 100 Of type All Traffic To the Destination 0.0.0.0/0 And a Allow Behavior After Saving you would then use Subnet Associations to Edit Subnet Associations . Here you would Associate with the Web App Public Subnet in AZ1 and Web App Public Subnet in AZ2 subnets by selecting the subnets and clicking Save changes . Now, you\u2019ve effectively ensured that if the Load Balancers in your environment misbehave, they can\u2019t communicate with or compromise the Database servers directly. But there was no additional hardware, firewall, or complex routing required to make this simple change in the simple network topology. But let\u2019s say you want to go further. The Proof of Concept servers you built aren\u2019t exchanging state so they don\u2019t need to communicate to each other. This way, if one gets compromised it can\u2019t hurt the other. Let\u2019s build that protection. You would Create a network ACL . Name it \u201c PoCProtectionAZ1 \u201d and put it in the Proof of Concept VPC . Select the new ACL, and add an Outbound Rule by Editing Outbound Rules Add Rules Rule #: 50 Of type All Traffic To the Destination 10.250.128.0/24 And a Deny Behavior and Rule #: 100 Of type All Traffic To the Destination 0.0.0.0/0 And an Allow Behavior Save the rules and allow access to that subnet from the internet. Edit inbound Rules and Add Rule Rule #: 100 Of type All Traffic To the Destination 0.0.0.0/0 And an Allow Behavior After Saving you would then use Subnet Associations to Edit Subnet Associations . Here you would Associate with the Proof of Concept Public Subnet in AZ1 subnets by selecting it and clicking Save Changes . You can choose to duplicate those steps to block the other direction by setting Name to \u201c PoCProtectionAZ2 \u201d Blocking traffic to the Destination 10.250.0.0/24 And Associating with Proof of Concept Public Subnet in AZ2 Now, even within the same workload or application you are protecting servers from each other where putting Firewalls in the past would have been impossible. Logging actions in your environment and making it easy to see what\u2019s changed We just made a bunch of changes, and on-premises it may be difficult to track them. Let\u2019s check the CloudTrail in Services to see what it noticed. The Dashboard shows us some recent events, but we want to see the complete Event History . Here we can see your User Name performing actions tracked by Event name against different Resource Names . API commands not related to Data (because we chose that earlier) are being captured by CloudTrail. You can remove the system calls by using a Filter on User Name and putting your User Name in the text box and hitting enter. Now Scroll down . Do you see all the ACL\u2019s you changed? But again, seeing these API calls doesn\u2019t give you a good visual of the changes occurring. Let's go to Config . I can see all of my resources, including some called EC2 NetworkAcl . Clicking there gives you a list of ACL\u2019s, and you can click on the first one. Seeing details on that ACL, you can also see a visual Resource Timeline In the configuration timeline, you can see the changes that occurred over the past few minutes. If you don\u2019t see any changes go back and choose a different ACL If you expand the Configuration change item, you can see exactly what changes you made to the resource, including what you applied it to as a \"Relationship Change\". How would you do this on-premises? Logging and monitoring of the network for bad behavior is important too Let\u2019s go back to GuardDuty and see what findings we may have. If this is a new or infrequently used account, you may have no Findings. If you do have Findings and this is not a new account, we can walk through those separately. Since this is a good design and relatively new, let\u2019s create some demonstration findings in Settings After we Generate sample findings we can go back to the Findings You'll see some High Severity, Medium Severity, and Informational Findings. Let\u2019s investigate the High Severity finding called [SAMPLE] [SAMPLE] Backdoor:EC2/C CActivity.B!DNS You can see the (fake) instance that caused this Finding, what the instance did wrong, when it occurred, and more information. The \u201c.Dns\u201d at the end means something, do you know what? Does the Action Type help? What are the 3 data sources GuardDuty uses? Scrolling down the Findings list again you see another severity of type Behavior:EC2/TrafficVolumeUnusual Here you see a lot of the same type of information. But why is this Action Type different? If we didn\u2019t turn on those logs how did it see the traffic? Scrolling down the Findings list a bit more you find a finding for Policy:IAMUser/RootCredentialUsage This one not only has a different Action Type but also starts with IAMUser instead of EC2 . Why does that matter? Is this a different data source? Now you\u2019ve seen that GuardDuty is monitoring logs on your behalf, and without you having to pay for storage, the AI/ML or Threat feeds, and the hours to do the analysis. This is all happening at Cloud scale too, no longer do you need to have terabytes of logs that are never touched. Reducing the risk of Admin access and administrative ports Finally, let's further reduce administrative risks by reducing access and improving logging. With our current setup, there is still a risk of open administrative ports, right? It's a bigger risk if those ports are open to the internet and a smaller risk if open internally for malware to find. Can we find a way around this requirement? Let\u2019s go back to VPC and Security Groups . Open the Services Server Security Group and the Inbound Rules . Now, despite the fact that those are made up IPs, you are going to Edit Rules and delete all the rules (Click the x on the right). Then Save and Close . But with no access, how can we monitor or log into the box if we need to? Our Service called Systems Manager can help there. Systems Manager has a feature called Session Manager worth checking out. At Sessions , you can Start a session with any server with the SSM agent and access to the SSM Service. We disabled all access to the Services Server for AZ1 , yet there it is. Let\u2019s select it and Start session . Is this a console? For the AWS server? Let\u2019s find out. Type: TOKEN=`curl -X PUT http://169.254.169.254/latest/api/token -H X-aws-ec2-metadata-token-ttl-seconds: 21600 ` curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/instance-id Does that instance ID look familiar? curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/security-groups That looks like the Security Group we modified doesn\u2019t it? ping 1.1.1.1 Should it work? curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/iam/security-credentials/SharedServerConnectivityRole Sure looks like an AWS server. Congratulations! You have successfully set up this AWS environment for strong logging with Cloudtrail and Config, granular communication with Security Groups and NACLs, intelligent threat detection with AWS GuardDuty, and configured your machines to have safe administrative access without requiring access from the public internet. If you have reached the bottom of this page with time to spare, there is Extra Credit available. Finally, make sure to Clean up your environment to ensure you don't have any continuing charges.","title":"Lab"},{"location":"labsteps/#mitigate-risks-using-cloud-native-infrastructure-security","text":"","title":"Mitigate Risks Using Cloud-Native Infrastructure Security"},{"location":"labsteps/#lab-sections","text":"Enable granular logging Improve granular control of communication Improve granular network-based controls Evaluate detailed logging capabilities Evaluate network-based protections Minimize admin access risk","title":"Lab Sections"},{"location":"labsteps/#enable-granular-logging-to-see-everything-in-your-aws-environment","text":"We want to enable detailed, holistic logging and network-based security monitoring. Go to the CloudTrail service in the console. If it appears, click on Getting Started. We want to Create trail . Let\u2019s set a Trail Name of \u201c All-API-Commands-across-all-Regions \u201d. We should save these for further evaluation, so you would want to Create a new S3 bucket and call it \u201c cloudsecurity-demo-bucket-{myname} \u201d. (Don\u2019t forget, S3 buckets must have unique names, so make sure to add your name at the end. They can also only be lower case letters, numbers, \u201c-\u201c, and \u201c.\u201d) Log file encryption will be enabled by default. Give it the name of a new KMS key to use for the encryption by specifiying \" cloudsecurity-demo-kms-key \". Now we'll get the option to pick what Events we want to record. Make sure to select Management Events , with Read / Write activity, at minimum. These options will show us every API call made to our AWS environment moving forward. What are your other options? When would you want to enable those? Click Create to finalize the trail. We can come back to look at the results later. Monitoring what API calls are made is great, but it\u2019s difficult to convert that into something like Change Management for all infrastructure in the cloud. Is there a service to help there? Let us also look into one of the Services called Config . After Getting Started we can start tracking All resources, Including Global Resources AWS does a good job of clearly defining roles, so let\u2019s allow AWS to Create AWS Config service-linked role We would want to store this data in a central bucket as well. Let\u2019s Create a new bucket and use the default to ensure it's unique. Note: We could use the bucket we just created, but you would have to add permissions, which would take more time. Next , we can choose rules we want to test against, but we can do that later too if we skip it for now. Confirm these choices to enable Config to monitor all changes to our environment. And we\u2019ll see that in a bit. Now that we\u2019ve got good logging of the Control Plane (API commands and Changes to the environment), let\u2019s turn on logging of the Data Plane. Then, let us use a Service like GuardDuty to monitor logs in near real time for security anomalies. After Getting Started we can quickly enable this service with just one click. It\u2019s that easy. We'll check out what GuardDuty monitoring is later. When we looked at our on-premises environment we identified that disjointed security tooling, lack of insight into what\u2019s going on in the environment, and difficulty managing change control and permissions in the environment all led to risks becoming problems pretty fast. With the services we just enabled, we\u2019ll see how we now have complete insight into who\u2019s doing what in the environment, what changes are being made, and if and when problems start to arise.","title":"Enable granular logging to see everything in your AWS environment"},{"location":"labsteps/#granular-provable-control-of-communications","text":"Let's review and improve upon granular control of communication between workloads in the cloud. Looking at the granular control of system-to-system communication used to be difficult. Now, looking at your EC2 Service Security Groups allows you to quickly see who can talk to whom. Picking a Security Group like the Services Server Security Group we can see the more traditional way of doing things. Checking the Outbound rules, we see the servers can talk to a range of IP\u2019s, 65,536 to be precise. But there are only maybe 6-8 servers that they actually need to talk to. Well, if we copy the Security Group ID of the PoC Web Server Security Group we can start to reduce that number Edit the Outbound set of rules for the Services Server Security Group . Delete the 10.0.0.0/16 rule. Then, make a new rule with the Security Group name you copied. Save this and you\u2019ll see the Destination of the rule now shows the Security Group you listed. You can repeat this by Edit ing and Adding Rule s for each security group you want to allow access to. In doing this, you\u2019ve reduced the scope of internal traffic communication from 65,636 host down to 8. Additionally, if you ever need to stand up more servers in these groups, they would be automatically accessible without intervention, as long as you put them in the same Security Group. On premise, you would either need to have Firewalls between all internal VLAN\u2019s, Routers, and sites or complex Network ACL\u2019s on every switch in your environment. This reduces the risk of threats, the risk of misconfiguration, and the operational burden all at once.","title":"Granular, Provable Control of Communications"},{"location":"labsteps/#when-security-includes-explicitly-denying-network-access","text":"Let's improve on our network-based controls by using Network ACLs to prevent lateral movement in a granular way. Security Groups are awesome at allowing access, but in VPC Services, Network ACLs are great at explicitly blocking them. For instance, if you wanted to make sure you explicitly blocked the Load Balancer in my WebApp from talking to my Database servers, you could Create a network ACL . You can name it \u201c LoadBalancerIsolation \u201d and put it in the Web Application VPC . After selecting the new network ACL, add an Outbound Rule by Editing Outbound Rules Adding Rules like these would block whatever Subnet you apply this to from talking to the Database Subnets but still allow access to the rest of the network, including the Web and Services VPC. Note that NACLs are evaluated in the specific order of their Rule #. Rule #: 50 Of type All Traffic To the Destination 10.0.2.0/24 And a Deny Behavior and Rule #: 60 Of type All Traffic To the Destination 10.0.130.0/24 And a Deny Behavior and Rule #: 100 Of type All Traffic To the Destination 0.0.0.0/0 And an Allow Behavior After Saving you need to allow access to that subnet from the internet, so recreating the All Traffic Allow rule for Inbound Rules is necessary. Add a Rule Rule #: 100 Of type All Traffic To the Destination 0.0.0.0/0 And a Allow Behavior After Saving you would then use Subnet Associations to Edit Subnet Associations . Here you would Associate with the Web App Public Subnet in AZ1 and Web App Public Subnet in AZ2 subnets by selecting the subnets and clicking Save changes . Now, you\u2019ve effectively ensured that if the Load Balancers in your environment misbehave, they can\u2019t communicate with or compromise the Database servers directly. But there was no additional hardware, firewall, or complex routing required to make this simple change in the simple network topology. But let\u2019s say you want to go further. The Proof of Concept servers you built aren\u2019t exchanging state so they don\u2019t need to communicate to each other. This way, if one gets compromised it can\u2019t hurt the other. Let\u2019s build that protection. You would Create a network ACL . Name it \u201c PoCProtectionAZ1 \u201d and put it in the Proof of Concept VPC . Select the new ACL, and add an Outbound Rule by Editing Outbound Rules Add Rules Rule #: 50 Of type All Traffic To the Destination 10.250.128.0/24 And a Deny Behavior and Rule #: 100 Of type All Traffic To the Destination 0.0.0.0/0 And an Allow Behavior Save the rules and allow access to that subnet from the internet. Edit inbound Rules and Add Rule Rule #: 100 Of type All Traffic To the Destination 0.0.0.0/0 And an Allow Behavior After Saving you would then use Subnet Associations to Edit Subnet Associations . Here you would Associate with the Proof of Concept Public Subnet in AZ1 subnets by selecting it and clicking Save Changes . You can choose to duplicate those steps to block the other direction by setting Name to \u201c PoCProtectionAZ2 \u201d Blocking traffic to the Destination 10.250.0.0/24 And Associating with Proof of Concept Public Subnet in AZ2 Now, even within the same workload or application you are protecting servers from each other where putting Firewalls in the past would have been impossible.","title":"When Security includes explicitly denying network access"},{"location":"labsteps/#logging-actions-in-your-environment-and-making-it-easy-to-see-whats-changed","text":"We just made a bunch of changes, and on-premises it may be difficult to track them. Let\u2019s check the CloudTrail in Services to see what it noticed. The Dashboard shows us some recent events, but we want to see the complete Event History . Here we can see your User Name performing actions tracked by Event name against different Resource Names . API commands not related to Data (because we chose that earlier) are being captured by CloudTrail. You can remove the system calls by using a Filter on User Name and putting your User Name in the text box and hitting enter. Now Scroll down . Do you see all the ACL\u2019s you changed? But again, seeing these API calls doesn\u2019t give you a good visual of the changes occurring. Let's go to Config . I can see all of my resources, including some called EC2 NetworkAcl . Clicking there gives you a list of ACL\u2019s, and you can click on the first one. Seeing details on that ACL, you can also see a visual Resource Timeline In the configuration timeline, you can see the changes that occurred over the past few minutes. If you don\u2019t see any changes go back and choose a different ACL If you expand the Configuration change item, you can see exactly what changes you made to the resource, including what you applied it to as a \"Relationship Change\". How would you do this on-premises?","title":"Logging actions in your environment and making it easy to see what\u2019s changed"},{"location":"labsteps/#logging-and-monitoring-of-the-network-for-bad-behavior-is-important-too","text":"Let\u2019s go back to GuardDuty and see what findings we may have. If this is a new or infrequently used account, you may have no Findings. If you do have Findings and this is not a new account, we can walk through those separately. Since this is a good design and relatively new, let\u2019s create some demonstration findings in Settings After we Generate sample findings we can go back to the Findings You'll see some High Severity, Medium Severity, and Informational Findings. Let\u2019s investigate the High Severity finding called [SAMPLE] [SAMPLE] Backdoor:EC2/C CActivity.B!DNS You can see the (fake) instance that caused this Finding, what the instance did wrong, when it occurred, and more information. The \u201c.Dns\u201d at the end means something, do you know what? Does the Action Type help? What are the 3 data sources GuardDuty uses? Scrolling down the Findings list again you see another severity of type Behavior:EC2/TrafficVolumeUnusual Here you see a lot of the same type of information. But why is this Action Type different? If we didn\u2019t turn on those logs how did it see the traffic? Scrolling down the Findings list a bit more you find a finding for Policy:IAMUser/RootCredentialUsage This one not only has a different Action Type but also starts with IAMUser instead of EC2 . Why does that matter? Is this a different data source? Now you\u2019ve seen that GuardDuty is monitoring logs on your behalf, and without you having to pay for storage, the AI/ML or Threat feeds, and the hours to do the analysis. This is all happening at Cloud scale too, no longer do you need to have terabytes of logs that are never touched.","title":"Logging and monitoring of the network for bad behavior is important too"},{"location":"labsteps/#reducing-the-risk-of-admin-access-and-administrative-ports","text":"Finally, let's further reduce administrative risks by reducing access and improving logging. With our current setup, there is still a risk of open administrative ports, right? It's a bigger risk if those ports are open to the internet and a smaller risk if open internally for malware to find. Can we find a way around this requirement? Let\u2019s go back to VPC and Security Groups . Open the Services Server Security Group and the Inbound Rules . Now, despite the fact that those are made up IPs, you are going to Edit Rules and delete all the rules (Click the x on the right). Then Save and Close . But with no access, how can we monitor or log into the box if we need to? Our Service called Systems Manager can help there. Systems Manager has a feature called Session Manager worth checking out. At Sessions , you can Start a session with any server with the SSM agent and access to the SSM Service. We disabled all access to the Services Server for AZ1 , yet there it is. Let\u2019s select it and Start session . Is this a console? For the AWS server? Let\u2019s find out. Type: TOKEN=`curl -X PUT http://169.254.169.254/latest/api/token -H X-aws-ec2-metadata-token-ttl-seconds: 21600 ` curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/instance-id Does that instance ID look familiar? curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/security-groups That looks like the Security Group we modified doesn\u2019t it? ping 1.1.1.1 Should it work? curl -H X-aws-ec2-metadata-token: $TOKEN http://169.254.169.254/latest/meta-data/iam/security-credentials/SharedServerConnectivityRole Sure looks like an AWS server. Congratulations! You have successfully set up this AWS environment for strong logging with Cloudtrail and Config, granular communication with Security Groups and NACLs, intelligent threat detection with AWS GuardDuty, and configured your machines to have safe administrative access without requiring access from the public internet. If you have reached the bottom of this page with time to spare, there is Extra Credit available. Finally, make sure to Clean up your environment to ensure you don't have any continuing charges.","title":"Reducing the risk of Admin access and administrative ports"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"setup/","text":"Build the environment using CloudFormation We will need an EC2 Key Pair to build this stack. Under Services , Compute go to EC2 . Select Key Pairs on the left. Create a Key Pair . Name the Key Pair \" CloudSecurityDemoKP \" and save the file to your desktop. We will not need the file, but a Key Pair must exist Now under Services open Management Governance , CloudFormation Click \u201c Create Stack \u201d Save this file to your desktop: InfraSecBuilderSessionEnvBuild.json In CloudFormation, choose upload a template file , and choose the json file you just downloaded. Fill out the screen as follows: Stack Name: \" CloudSecurity-Demo-Stack \" Availability Zone 1: Pick any availability zone Availability Zone 2: Pick any availability zone except the first one you picked LatestLinuxAmiID: Leave as default. PassedKeyName: \" CloudSecurityDemoKP \" Click \u201cNext\u201d Click \u201cNext\u201d on the following screen. Acknowledge the CloudFormation Template creates a user by checking the box. Note: People frequently miss this step Click \u201cCreate Stack\u201d Refresh the CloudFormation interface until the Status of the CloudSecurity demo stack shows \u201cCreate Complete\u201d Click on the Stack Name Go to the Outputs tab of the Stack Copy the following DNS names into a separate note pad. You can go to these in a web browser to validate that the Web servers are publicly accessible. The LoadBalancerFullDNS, PoCWebServer1PublicDNS, and PoCWebServer2PublicDNS should all work. Now we\u2019ve setup the environment. We can now move forward with your hands on portion .","title":"Set Up"},{"location":"setup/#build-the-environment-using-cloudformation","text":"We will need an EC2 Key Pair to build this stack. Under Services , Compute go to EC2 . Select Key Pairs on the left. Create a Key Pair . Name the Key Pair \" CloudSecurityDemoKP \" and save the file to your desktop. We will not need the file, but a Key Pair must exist Now under Services open Management Governance , CloudFormation Click \u201c Create Stack \u201d Save this file to your desktop: InfraSecBuilderSessionEnvBuild.json In CloudFormation, choose upload a template file , and choose the json file you just downloaded. Fill out the screen as follows: Stack Name: \" CloudSecurity-Demo-Stack \" Availability Zone 1: Pick any availability zone Availability Zone 2: Pick any availability zone except the first one you picked LatestLinuxAmiID: Leave as default. PassedKeyName: \" CloudSecurityDemoKP \" Click \u201cNext\u201d Click \u201cNext\u201d on the following screen. Acknowledge the CloudFormation Template creates a user by checking the box. Note: People frequently miss this step Click \u201cCreate Stack\u201d Refresh the CloudFormation interface until the Status of the CloudSecurity demo stack shows \u201cCreate Complete\u201d Click on the Stack Name Go to the Outputs tab of the Stack Copy the following DNS names into a separate note pad. You can go to these in a web browser to validate that the Web servers are publicly accessible. The LoadBalancerFullDNS, PoCWebServer1PublicDNS, and PoCWebServer2PublicDNS should all work. Now we\u2019ve setup the environment. We can now move forward with your hands on portion .","title":"Build the environment using CloudFormation"}]}